u<-read.csv("F:/Soils/SoilEnvironmentaldataUSGSApril.csv",header=TRUE, row.names=1)
p<-read.csv("F:/Soils/SoilEnvironmentaldataNSplain.csv",header=TRUE, row.names=1)
a<-read.csv("F:/Soils/SoilEnvironmentaldataApril.csv",header=TRUE, row.names=1)
z <- subset(u, select = -c(SlopeShape,DepthClass,H1.Texture,H1.SandSize,Tot.Texture,Tot.SandSize) )
pearson <- cor(z, method = c("pearson"),use = "complete.obs")
kendall <- cor(z, method = c("kendall"),use = "complete.obs")
spearman <- cor(z, method = c("spearman"),use = "complete.obs")
# write.csv(spearman,file="F:/SpearmanSoilCorrelation.csv", row.names=TRUE)
# install.packages("Hmisc")
library(Hmisc)
# ++++++++++++++++++++++++++++
# flattenCorrMatrix
# ++++++++++++++++++++++++++++
# cormat : matrix of the correlation coefficients
# pmat : matrix of the correlation p-values
flattenCorrMatrix <- function(cormat, pmat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut],
p = pmat[ut]
)
}
res<-rcorr(as.matrix(z[,1:42]), type=c("spearman"))
corPval <- flattenCorrMatrix(res$r, res$P)
q <- symnum(spearman)
Susan7 <- corPval[ which((corPval$cor >= 0.7)|(corPval$cor < -0.7)),]
Susan8 <- corPval[ which((corPval$cor >= 0.8)|(corPval$cor < -0.8)),]
# Sagebrush Count by Transect
library(plyr)
##########################  LPI   ####################################
# read in all LPI data by transect
lpi <- read.csv("F:/LPI/USGSLPIofAprilAndUSGS.csv", header=T)
lpi <- lpi[,-c(1,2,6,7,9)] # remove extraneous columns
table(lpi$Indicator)
# break up in to live and dead sagebrush
# Live
lpi.l <- subset(lpi, Indicator %in% "ARTR2") # select only rows with ARTR2
dp <- subset(lpi, Indicator %in% "ARTR2/DP")# select only rows with ARTR2/DP
lpi.l <- merge(lpi.l,dp,by=c("Plot","Line")) #Combine ARTR2 and ARTR2/DP
lpi.l$total <- lpi.l$Any.Hit.N.x + lpi.l$Any.Hit.N.y # add ARTR and ARTR/DP totals
lpi.l <- lpi.l[-c(1,2,3),c(1,2,3,7)] # remove extra columns and usgs1 (no artr, not in density)
lpi.l <- rename(lpi.l, replace = c("Indicator.x" = "species")) # rename species column
lpi.l <- lpi.l[order(lpi.l$Plot),]  #sort a dataframe by the order of the elements in Plot
rownames(lpi.l) <- NULL # remove extra row.names column
lpi.l.m<-xtabs(total~Plot+Line, lpi.l) # put in plot by transect matrix
write.csv(lpi.l.m,file="F:/SagebrushCount/lpi.l.csv")
# Dead
lpi.d <- subset(lpi, Indicator %in% "ARTR2/D") # select only rows with ARTR2/D
lpi.d <- rename(lpi.d, replace = c("Indicator" = "species", "Any.Hit.N" = "total")) # rename species column
lpi.d <- lpi.d[order(lpi.d$Plot),]  #sort a dataframe by the order of the elements in SpeciesCode
lpi.d <- lpi.d[-c(1,2,3),] # remove usgs1 (no artr, not in density)
rownames(lpi.d) <- NULL # remove extra row.names column
lpi.d.m<-xtabs(total~Plot+Line, lpi.d) # put in plot by transect matrix
write.csv(lpi.d.m,file="F:/SagebrushCount/lpi.d.csv")
#######################   Density   ############################
# read in all Density data by transect
den <- read.csv("F:/SagebrushCount/PlantDenSpeciesSummary 8-21AddLPImisses.csv", header=T)
# break up into live and dead sagebrush
den.l <- subset(den, Species %in% "ARTR2") # select only rows with ARTR2
rownames(den.l) <- NULL # remove extra row.names column
den.d <- subset(den, Species %in% "ARTR2/D") # select only rows with ARTR2/D
rownames(den.d) <- NULL # remove extra row.names column
# plot by transect
plotxtransect<-xtabs(Total~Plot+Line, den.l) # put in plot by spp matrix
write.csv(plotxtransect,file="F:/SagebrushCount/den.l.plotxtransect.csv")
plotxtransect<-xtabs(Total~Plot+Line, den.d) # put in plot by spp matrix
write.csv(plotxtransect,file="F:/SagebrushCount/den.d.plotxtransect.csv")
#################### Combine LPI & Density ######################
### Live
# read in lpi and density data
# seperate usgs and april data
l.lpi <- read.csv("F:/SagebrushCount/lpi.l.csv", header=T, row.names = 1)
a.l.lpi <- l.lpi[c(61:159),] # keep only april data
u.l.lpi <- l.lpi[c(1:60),] # keep only usgs data
l.den <- read.csv("F:/SagebrushCount/den.l.plotxtransect.csv", header=T, row.names = 1)
a.l.den <- l.den[c(61:159),] # keep only april data
u.l.den <- l.den[c(1:60),] # keep only usgs data
# combine lpi and density data
# rename columns
l <- merge(a.l.lpi,a.l.den,by="row.names") #Combine live lpi and density
l$T1 <- l$X1.x + l$X1.y # add lpi and density totals
l$T2 <- l$X2.y
l$T3 <- l$X3.y
l$T4 <- l$X4.y
l$T5 <- l$X5.x + l$X5.y # add lpi and density totals
l <- l[,-c(2:11)] # remove extra columns
rownames(l) <- l$Row.names
l$Row.names <- NULL
# live/live transect totals
l.relcover <- (l/rowSums(l))*100
write.csv((format(l.relcover, digits=2)),file="F:/SagebrushCount/lrelcover.csv")
### Dead
# read in lpi and density data
# seperate usgs and april data
d.lpi <- read.csv("F:/SagebrushCount/lpi.d.csv", header=T, row.names = 1)
a.d.lpi <- d.lpi[c(61:159),] # keep only april data
u.d.lpi <- d.lpi[c(1:60),] # keep only usgs data
d.den <- read.csv("F:/SagebrushCount/den.d.plotxtransect.csv", header=T, row.names = 1)
a.d.den <- d.den[c(61:159),] # keep only april data
u.d.den <- d.den[c(1:60),] # keep only usgs data
# combine lpi and density data
# rename columns
d <- merge(a.d.lpi,a.d.den,by="row.names") #Combine dead lpi and density
d$T1 <- d$X1.x + d$X1.y # add lpi and density totals
d$T2 <- d$X2.y
d$T3 <- d$X3.y
d$T4 <- d$X4.y
d$T5 <- d$X5.x + d$X5.y # add lpi and density totals
d <- d[,-c(2:11)] # remove extra columns
rownames(d) <- d$Row.names
d$Row.names <- NULL
# dead/dead transect totals
d.relcover <- (d/rowSums(d))*100
write.csv((format(d.relcover, digits=2)),file="F:/SagebrushCount/drelcover.csv")
# Combine live and dead into one document
ld.rel <- merge(l.relcover,d.relcover,by="row.names") #Combine live and dead data
names(ld.rel) <- c("Plot","T1.L","T2.L","T3.L","T4.L","T5.L","T1.D","T2.D","T3.D","T4.D","T5.D")
write.csv((format(ld.rel, digits =3)),file="F:/SagebrushCount/ldpercentspp.csv", row.names=FALSE)
################# Combine Live and Dead ######################
ld <- merge(l,d,by="row.names") #Combine live and dead data
rownames(ld) <- ld$Row.names
ld$Row.names <- NULL
relcover <- (ld/rowSums(ld))*100
write.csv((format(relcover, digits=2)),file="F:/SagebrushCount/ldrelcover.csv")
ld$Live <- ld$T1.x + ld$T2.x + ld$T3.x + ld$T4.x + ld$T5.x # add lpi and density totals
ld$Total <- ld$T1.x + ld$T2.x + ld$T3.x + ld$T4.x + ld$T5.x +
ld$T1.y + ld$T2.y + ld$T3.y + ld$T4.y + ld$T5.y
ld$LiveTotal <- (ld$Live/ld$Total)*100
ld$Dead <- ld$T1.y + ld$T2.y + ld$T3.y + ld$T4.y + ld$T5.y # add lpi and density totals
ld$DeadTotal <- (ld$Dead/ld$Total)*100
percent <- merge(relcover,ld,by="row.names") #Combine live and dead data
percent <- percent[,-c(12:23,25)] # remove extra columns
names(percent) <- c("Plot","T1.L","T2.L","T3.L","T4.L","T5.L","T1.D","T2.D","T3.D","T4.D","T5.D","LiveTotal","DeadTotal")
write.csv((format(percent, digits =3)),file="F:/SagebrushCount/ldpercent.csv", row.names=FALSE)
################## Total live #################################
################## Total dead #################################
############# Percent Live Plot Level #########################
## LPI
l.lpi <- read.csv("F:/SagebrushCount/lpi.l.csv", header=T, row.names = 1)
l.lpi$LPI.LiveCount <- rowSums(l.lpi)
d.lpi <- read.csv("F:/SagebrushCount/lpi.d.csv", header=T, row.names = 1)
l.lpi$LPI.DeadCount <- rowSums(d.lpi)
l.lpi <- l.lpi[,-c(1:5)] # remove extra columns
l.lpi$LPI.PctLive <- (l.lpi$LPI.LiveCount/rowSums(l.lpi))*100
## Density
l.den <- read.csv("F:/SagebrushCount/den.l.plotxtransect.csv", header=T, row.names = 1)
l.den$DEN.LiveCount <- rowSums(l.den)
d.den <- read.csv("F:/SagebrushCount/den.d.plotxtransect.csv", header=T, row.names = 1)
l.den$DEN.DeadCount <- rowSums(d.den)
l.den <- l.den[,-c(1:5)] # remove extra columns
l.den$DEN.PctLive <- (l.den$DEN.LiveCount/rowSums(l.den))*100
## Combine
geno <- merge(l.lpi,l.den,by="row.names") #Combine live and dead data
library(plyr)
##########################  LPI   ####################################
# read in all LPI data by transect
lpi <- read.csv("F:/LPI/USGSLPIofAprilAndUSGS.csv", header=T)
lpi <- read.csv("F:/LPI/Old/USGSLPIofAprilAndUSGS.csv", header=T)
lpi <- lpi[,-c(1,2,6,7,9)] # remove extraneous columns
table(lpi$Indicator)
View(lpi)
u<-read.csv("F:/Soils/SoilEnvironmentaldataUSGSApril.csv",header=TRUE, row.names=1)
p<-read.csv("F:/Soils/SoilEnvironmentaldataNSplain.csv",header=TRUE, row.names=1)
a<-read.csv("F:/Soils/SoilEnvironmentaldataApril.csv",header=TRUE, row.names=1)
z <- subset(u, select = -c(SlopeShape,DepthClass,H1.Texture,H1.SandSize,Tot.Texture,Tot.SandSize) )
pearson <- cor(z, method = c("pearson"),use = "complete.obs")
kendall <- cor(z, method = c("kendall"),use = "complete.obs")
spearman <- cor(z, method = c("spearman"),use = "complete.obs")
# write.csv(spearman,file="F:/SpearmanSoilCorrelation.csv", row.names=TRUE)
# install.packages("Hmisc")
library(Hmisc)
# ++++++++++++++++++++++++++++
# flattenCorrMatrix
# ++++++++++++++++++++++++++++
# cormat : matrix of the correlation coefficients
# pmat : matrix of the correlation p-values
flattenCorrMatrix <- function(cormat, pmat) {
ut <- upper.tri(cormat)
data.frame(
row = rownames(cormat)[row(cormat)[ut]],
column = rownames(cormat)[col(cormat)[ut]],
cor  =(cormat)[ut],
p = pmat[ut]
)
}
res<-rcorr(as.matrix(z[,1:42]), type=c("spearman"))
corPval <- flattenCorrMatrix(res$r, res$P)
q <- symnum(spearman)
Susan7 <- corPval[ which((corPval$cor >= 0.7)|(corPval$cor < -0.7)),]
Susan8 <- corPval[ which((corPval$cor >= 0.8)|(corPval$cor < -0.8)),]
write.csv(Susan7,file="F:/Soil.7SpearmansCorrelation.csv", row.names=TRUE)
Den <- read.csv("F:/LPI/Output/AprilLPIDensityM2.csv",header=TRUE, row.names=1)
Soil <- read.csv("F:/Soils/SoilEnvironmentaldataApril.csv",header=TRUE, row.names=1)
ARTR2 <- Den$ARTR2
artr <- cbind(Soil,ARTR2) ; artr <- artr[, !sapply(artr, is.factor)]
# ARTR2 + Half of Min Non-Zero
trfHalf <- ARTR2+((min(ARTR2[ARTR2 > 0]))*0.5)
trfHalf <- cbind(Soil,trfHalf); trfHalf <- trfHalf[, !sapply(trfHalf, is.factor)]
# Log ARTR2 + Half of Min Non-Zero
logHalf <- log(ARTR2+((min(ARTR2[ARTR2 > 0]))*0.5))
logHalf <- cbind(Soil,logHalf); logHalf <- logHalf[, !sapply(logHalf, is.factor)]
# log transform
log <- log(ARTR2)
log[mapply(is.infinite, log)] <- 0
log <- cbind(Soil,log); log <- log[, !sapply(log, is.factor)]
# log10 transform
log10 <- log10(ARTR2)
log10[mapply(is.infinite, log10)] <- 0
log10 <- cbind(Soil,log10); log10 <- log10[, !sapply(log10, is.factor)]
# log(x+1) transform
log1 <- log(ARTR2+1)
log1 <- cbind(Soil,log1); log1 <- log1[, !sapply(log1, is.factor)]
# Square Root transform
sqrt <- sqrt(ARTR2)
sqrt <- cbind(Soil,sqrt);sqrt <- sqrt[, !sapply(sqrt, is.factor)]
# Cube Root transform
cube <- (ARTR2)^(1/3)
cube <- cbind(Soil,cube); cube <- cube[, !sapply(cube, is.factor)]
# log(x+c) transform
logc <- log(ARTR2+.000000001)
logc <- cbind(Soil,logc); logc <- logc[, !sapply(logc, is.factor)]
# panel.smooth function is built in.
# panel.cor puts correlation in upper panels, size proportional to correlation
panel.cor <- function(x, y, digits=2, prefix="", cex.cor, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y))
txt <- format(c(r, 0.123456789), digits=digits)[1]
txt <- paste(prefix, txt, sep="")
if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex.cor * r)
}
# Clay
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+ARTR2,data=artr,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Clay Variables")
# ARTR2 + Half of smallest NonZero value
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+ARTR2,data=trfHalf,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Half NonZero Clay Variables")
# Log of ARTR2 + Half of smallest NonZero value
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+ARTR2,data=logHalf,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="logHalf NonZero Clay Variables")
# LogClay
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+log,data=log,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Log Clay Variables")
# Log10Clay
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+log10,data=log10,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Log 10 Clay Variables")
# Log(x+1)Clay
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+log1,data=log1,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Log(x+1)Clay Variables")
# Square Root
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+sqrt,data=sqrt,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Square Root Clay Variables")
# Cube Root
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+cube,data=cube,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Cube Root Clay Variables")
# Log(x+c)Clay
pairs(~MaxClay+DWAClay+H1.ClayPercent+Clay.50+logc,data=logc,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Log(x+c)Clay Variables")
# Sand
pairs(~MaxSand+DWASand+H1.SandPercent+Sand.50+ARTR2,data=logHalf,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Sand Variables")
# Boruta
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+ARTR2,data=artr,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Boruta Variables")
# ARTR2 + Half of smallest NonZero value
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+ARTR2,data=trfHalf,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Half NonZero Boruta Variables")
# Log of ARTR2 + Half of smallest NonZero value
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+ARTR2,data=logHalf,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="logHalf NonZero Boruta Variables")
# LogBoruta
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+log,data=log,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Log Boruta Variables")
# Log10Boruta
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+log10,data=log10,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Log 10 Boruta Variables")
# Log(x+1)Boruta
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+log1,data=log1,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Log(x+1)Boruta Variables")
# Square Root
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+sqrt,data=sqrt,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Square Root Boruta Variables")
# Cube Root
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+cube,data=cube,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Cube Root Boruta Variables")
# Log(x+c)Boruta
pairs(~MaxClay+H1.ClayPercent+MaxAWHC+PedonDepth+logc,data=logc,
lower.panel=panel.smooth, upper.panel=panel.cor,
pch=20, na.action = na.exclude, main="Log(x+c)Boruta Variables")
summary(Den)
summary(Soil)
?zeroinfl
summary(Den)
library(VGAM)
u<-read.csv("F:/Soils/SoilEnvironmentaldataUSGSApril.csv",header=TRUE, row.names=1)
u.den <- read.csv("F:/LPI/Output/USGSLPIDensityM2.csv",header=TRUE, row.names=1)
u$ARTR2 <- u.den$ARTR2
u1 <- subset(u, select = -c(Sand.50,Clay.50,pH.50,DryValue.50,EfferScale.50,AWHC.50,MaxClay,DWASand,DWA.AWHC,Tot.Texture,SlopeShape,DepthClass,H1.Texture,H1.SandSize))
u2 <- subset(u, select = -c(DWAClay,DWASand,DWApH,DWA.AWHC,AWHC.50,Sand.50,H1.Texture,H1.SandSize,Tot.Texture,Tot.SandSize,PedonDepth,Depth200,SlopeShape))
model.pois = glm(ARTR2 ~ ., data = u1, family = poisson)
warnings()
u<-read.csv("F:/Soils/SoilEnvironmentaldataUSGSApril.csv",header=TRUE, row.names=1)
u.den <- read.csv("F:/LPI/Output/USGSLPIDensityM2.csv",header=TRUE, row.names=1)
u$ARTR2 <- u.den$ARTR2
u$ARTR2 <- u$ARTR2*150
u1 <- subset(u, select = -c(Sand.50,Clay.50,pH.50,DryValue.50,EfferScale.50,AWHC.50,MaxClay,DWASand,DWA.AWHC,Tot.Texture,SlopeShape,DepthClass,H1.Texture,H1.SandSize))
u2 <- subset(u, select = -c(DWAClay,DWASand,DWApH,DWA.AWHC,AWHC.50,Sand.50,H1.Texture,H1.SandSize,Tot.Texture,Tot.SandSize,PedonDepth,Depth200,SlopeShape))
View(`u1`)
View(u)
u<-read.csv("F:/Soils/SoilEnvironmentaldataUSGSApril.csv",header=TRUE, row.names=1)
u.den <- read.csv("F:/LPI/Output/USGSLPIDensityM2.csv",header=TRUE, row.names=1)
u<-read.csv("F:/Soils/SoilEnvironmentaldataUSGSApril.csv",header=TRUE, row.names=1)
u.den <- read.csv("F:/LPI/Output/USGSLPIDensityM2.csv",header=TRUE, row.names=1)
u.count <- u.den*150
View(u.count)
View(u.count)
u.count <- u.den[c(1:37),]*90
a.count <- u.den[c(38:136),]*150
View(a.count)
View(u.count)
rbind(u.count,a.count)
count <- rbind(u.count,a.count)
View(count)
u$ARTR2 <- count$ARTR2
View(u)
u1 <- subset(u, select = -c(Sand.50,Clay.50,pH.50,DryValue.50,EfferScale.50,AWHC.50,MaxClay,DWASand,DWA.AWHC,Tot.Texture,SlopeShape,DepthClass,H1.Texture,H1.SandSize))
u2 <- subset(u, select = -c(DWAClay,DWASand,DWApH,DWA.AWHC,AWHC.50,Sand.50,H1.Texture,H1.SandSize,Tot.Texture,Tot.SandSize,PedonDepth,Depth200,SlopeShape))
model.pois = glm(ARTR2 ~ ., data = u1, family = poisson)
summary(model.pois.3)
summary(model.pois)
pchisq(summary(model.pois)$deviance,
summary(model.pois)$df.residual
)
cbind(nd,
Mean = predict(model.pois, newdata = nd, type = "response"),
SE = predict(model.pois, newdata = nd, type = "response", se.fit = T)$se.fit
)
cbind(nd,
Mean = predict(model.pois, newdata = u1, type = "response"),
SE = predict(model.pois, newdata = u1, type = "response", se.fit = T)$se.fit
)
cbind(u1,
Mean = predict(model.pois, newdata = u1, type = "response"),
SE = predict(model.pois, newdata = u1, type = "response", se.fit = T)$se.fit
)
library(pscl)
install.packages("pscl")
library(pscl)
model.zip = zeroinfl(ARTR2 ~ ., data = u1)
summary(model.zip)
library(pscl)
model.zip = zeroinfl(ARTR2 ~ ., data = u1)
summary(model.zip)
model.zip = zeroinfl(ARTR2 ~ ., data = u1)
?zeroinfl
model.pois = glm(ARTR2 ~ ., data = u1, family = poisson,offset=u.den$ARTR2)
summary(model.pois)
model.zip = zeroinfl(ARTR2 ~ ., data = u1,offset=u.den$ARTR2,dist="poisson")
